{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0934716b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pinak\\Documents\\GitHub\\non-grad3D\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fc21c2edf617>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0march\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_probability\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\site-packages\\tensorflow_probability\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# `python/__init__.py` as necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msubstrates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;31m# from tensorflow_probability.google import staging  # DisableOnExport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# from tensorflow_probability.google import tfp_google  # DisableOnExport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\site-packages\\tensorflow_probability\\substrates\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mall_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlazy_loader\u001b[0m  \u001b[1;31m# pylint: disable=g-direct-tensorflow-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\site-packages\\tensorflow_probability\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    140\u001b[0m   \u001b[1;31m# Non-lazy load of packages that register with tensorflow or keras.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mpkg_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_maybe_nonlazy_load\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpkg_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Forces loading the package from its lazy loader.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\site-packages\\tensorflow_probability\\python\\internal\\lazy_loader.py\u001b[0m in \u001b[0;36m__dir__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\site-packages\\tensorflow_probability\\python\\internal\\lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_on_first_access\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m# Import the target module and insert it into the parent's namespace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\site-packages\\tensorflow_probability\\python\\experimental\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mauto_batching\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbijectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlazybones\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\site-packages\\tensorflow_probability\\python\\experimental\\distribute\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_lib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_sharded_log_prob_parts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoint_distribution\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mJointDistributionCoroutine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoint_distribution\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mJointDistributionNamed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoint_distribution\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mJointDistributionSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\site-packages\\tensorflow_probability\\python\\experimental\\distribute\\joint_distribution.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdistribution_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoint_distribution\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjd_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta_binomial\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBetaBinomial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinomial\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBinomial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblockwise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBlockwise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcauchy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCauchy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pinak\\.conda\\envs\\py38\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "script_dir = Path(os.path.dirname(os.path.abspath('')))\n",
    "module_dir = str(script_dir)\n",
    "sys.path.insert(0, module_dir + '/modules')\n",
    "print(module_dir)\n",
    "\n",
    "# import the rest of the modules\n",
    "%matplotlib nbagg\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import arch\n",
    "import pandas as pd\n",
    "import tensorflow_probability as tfp\n",
    "import time  \n",
    "import sim\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "dim = 3\n",
    "n_particles = int(1e6)\n",
    "n_subdivisions = 10\n",
    "n_int_subdivs = 400\n",
    "save_folder = '../data/L63'\n",
    "n_steps = 10\n",
    "n_repeats = 1000\n",
    "dt = 0.01\n",
    "r = 5.0\n",
    "alpha, beta, rho = 10., 8./3., 28.\n",
    "sigma = 10.\n",
    "D = sigma**2 / 2.\n",
    "t = dt * n_steps\n",
    "\n",
    "# low=[-20., -20., -20.]\n",
    "# high=[20., 30., 80.]\n",
    "# domain = [low, high]\n",
    "\n",
    "def mu_np(X):\n",
    "    x, y, z = np.split(X, dim, axis=-1)\n",
    "    p = alpha * (y - x) \n",
    "    q = x * (rho - z) - y \n",
    "    r = x * y - beta * z\n",
    "    return np.concatenate([p, q, r], axis=-1)\n",
    "\n",
    "\n",
    "X0 =  tfp.distributions.MultivariateNormalDiag(scale_diag=r*tf.ones(dim)).sample(n_particles).numpy()\n",
    "mc_prob = sim.MCProb(save_folder, n_subdivisions, mu_np, sigma, X0, tick_size=20, title_size=20, cbar_tick_size=15)\n",
    "mc_prob.ready(n_steps=n_steps, dt=dt, lims=None)\n",
    "#mc_prob.compute_all(n_steps=n_steps, dt=dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a2ab1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_net(iter):\n",
    "    net = arch.LSTMForgetNet(num_nodes=50, num_blocks=3)\n",
    "    if iter < 500:\n",
    "        net.load_weights('../data/L63-true-vs-learned/init/L63_{}'.format(iter)).expect_partial()\n",
    "    elif iter < 10000:\n",
    "        net.load_weights('../data/L63-true-vs-learned/L63_{}'.format(iter)).expect_partial()\n",
    "    else:\n",
    "        net.load_weights('../data/L63/1M/L63').expect_partial()\n",
    "    return net\n",
    "\n",
    "\n",
    "\n",
    "s = 1.0\n",
    "# define drift\n",
    "def mu(X):\n",
    "    x, y, z = tf.split(X, [1, 1, 1], axis=-1)\n",
    "    p = alpha * (y - x)\n",
    "    q = x * (rho - s * z) - y \n",
    "    r = s * x * y - beta * z \n",
    "    return -tf.concat([p, q, r], axis=-1).numpy()\n",
    "\n",
    "n_theta = get_net(1000000)\n",
    "\n",
    "# define h0\n",
    "\n",
    "def h0(X):\n",
    "    l = len(X)\n",
    "    m = int(1e5)\n",
    "    M = int(np.ceil(l / m))\n",
    "    data = []\n",
    "    for i in range(M):\n",
    "        if i < M-1:\n",
    "            x_, y_, z_ = tf.split(X[i*m: (i+1)*m], [1, 1, 1], axis=-1)\n",
    "        else:\n",
    "            x_, y_, z_ = tf.split(X[i*m:], [1, 1, 1], axis=-1)\n",
    "        log_p0 = (- (x_**2 + y_**2 + z_**2) / (2.*r**2)).numpy()\n",
    "        log_pinf = n_theta(x_, y_, z_).numpy()\n",
    "        data.append(np.exp(log_p0 - log_pinf) / (2. * np.pi * r**2) ** (1.5))  \n",
    "    return np.concatenate(data, axis=0) \n",
    "    \n",
    "def sol(X):\n",
    "    l = len(X)\n",
    "    m = int(1e5)\n",
    "    M = int(np.ceil(l / m))\n",
    "    data = []\n",
    "    for i in range(M):\n",
    "        if i < M-1:\n",
    "            x_, y_, z_ = tf.split(X[i*m: (i+1)*m], [1, 1, 1], axis=-1)\n",
    "        else:\n",
    "            x_, y_, z_ = tf.split(X[i*m:], [1, 1, 1], axis=-1) \n",
    "        data.append(np.exp(n_theta(x_, y_, z_).numpy()))\n",
    "        \n",
    "    return np.concatenate(data, axis=0) \n",
    "\n",
    "\n",
    "\n",
    "grid = mc_prob.get_grid()\n",
    "low = grid.mins\n",
    "high = grid.maxs\n",
    "n_subdivs = n_subdivisions\n",
    "x = np.linspace(low[0], high[0], num=n_subdivs+1, endpoint=True).astype('float32')[1:]\n",
    "y = np.linspace(low[1], high[1], num=n_subdivs+1, endpoint=True).astype('float32')[1:]\n",
    "z = np.linspace(low[2], high[2], num=n_subdivs+1, endpoint=True).astype('float32')[1:]\n",
    "x, y, z = np.meshgrid(x, y, z, indexing='ij')\n",
    "x = x.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "z = z.reshape(-1, 1)\n",
    "x_ = np.linspace(low[0], high[0], num=n_subdivs, endpoint=True).astype('float32')\n",
    "y_ = np.linspace(low[1], high[1], num=n_subdivs, endpoint=True).astype('float32')\n",
    "z_ = np.linspace(low[2], high[2], num=n_subdivs, endpoint=True).astype('float32')\n",
    "iters = list(range(0, 500, 1)) + list(range(500, 10000, 100)) + [800000]*24\n",
    "nets = {iter: get_net(iter) for iter in iters}\n",
    "\n",
    "    \n",
    "fig_all = plt.figure(figsize=(16, 16))\n",
    "ax_1l = fig_all.add_subplot(321) \n",
    "ax_1m = fig_all.add_subplot(322)\n",
    "\n",
    "\n",
    "ax_2l = fig_all.add_subplot(323) \n",
    "ax_2m = fig_all.add_subplot(324)\n",
    "\n",
    "ax_3l = fig_all.add_subplot(325) \n",
    "ax_3m = fig_all.add_subplot(326)\n",
    "\n",
    "\n",
    "div_1 = make_axes_locatable(ax_1l)\n",
    "cax_1 = div_1.append_axes('right', '5%', '5%')\n",
    "div_2 = make_axes_locatable(ax_2l)\n",
    "cax_2 = div_2.append_axes('right', '5%', '5%')\n",
    "div_3 = make_axes_locatable(ax_3l)\n",
    "cax_3 = div_3.append_axes('right', '5%', '5%')\n",
    "\n",
    "tick_size = 15\n",
    "title_size = 20\n",
    "cbar_tick_size = 15\n",
    "\n",
    "z_m = mc_prob.compute_p2(0, 1, save=False)\n",
    "z_m  /= (z_m.sum() * grid.h[0] * grid.h[1])\n",
    "im = ax_1m.pcolormesh(x_, y_, z_m, cmap='inferno', shading='auto')\n",
    "cbar = fig_all.colorbar(im, ax=ax_1m)\n",
    "cbar.ax.tick_params(labelsize=cbar_tick_size)\n",
    "#cbar.formatter.set_powerlimits((0, 0))\n",
    "ax_1m.set_aspect(\"equal\")\n",
    "\n",
    "im = ax_2m.pcolormesh(y_, z_, mc_prob.compute_p2(1, 2, save=False), cmap='inferno', shading='auto')\n",
    "cbar = fig_all.colorbar(im, ax=ax_2m)\n",
    "cbar.ax.tick_params(labelsize=cbar_tick_size)\n",
    "#cbar.formatter.set_powerlimits((0, 0))\n",
    "ax_2m.set_aspect(\"equal\")\n",
    "\n",
    "im = ax_3m.pcolormesh(z_, x_, mc_prob.compute_p2(2, 0, save=False).T, cmap='inferno', shading='auto')\n",
    "cbar = fig_all.colorbar(im, ax=ax_3m)\n",
    "cbar.ax.tick_params(labelsize=cbar_tick_size)\n",
    "#cbar.formatter.set_powerlimits((0, 0))\n",
    "ax_3m.set_aspect(\"equal\")\n",
    "\n",
    "ax_1m.tick_params(axis='both', which='major', labelsize=tick_size)\n",
    "ax_1m.tick_params(axis='both', which='minor', labelsize=tick_size)\n",
    "ax_2m.tick_params(axis='both', which='major', labelsize=tick_size)\n",
    "ax_2m.tick_params(axis='both', which='minor', labelsize=tick_size)\n",
    "ax_3m.tick_params(axis='both', which='major', labelsize=tick_size)\n",
    "ax_3m.tick_params(axis='both', which='minor', labelsize=tick_size)\n",
    "\n",
    "ax_1m.set_title('Monte Carlo estimate', fontsize=title_size)\n",
    "ax_1m.set_xlabel('x', fontsize=title_size)\n",
    "ax_1m.set_ylabel('y', fontsize=title_size)\n",
    "ax_2m.set_xlabel('y', fontsize=title_size)\n",
    "ax_2m.set_ylabel('z', fontsize=title_size)\n",
    "ax_3m.set_xlabel('z', fontsize=title_size)\n",
    "ax_3m.set_ylabel('x', fontsize=title_size)\n",
    "\n",
    "\n",
    "\n",
    "fk = sim.FKSim3_2(save_folder='.', n_subdivs=n_subdivs, n_int_subdivs=n_int_subdivs, mu=mu, sigma=sigma, sol=sol, grid=grid, h0=h0)\n",
    "z_1l = fk.make_plot(n_steps, dt, n_repeats, 0, 1, 2)\n",
    "# z_1l, z_2l, z_3l = fk.compile(n_repeats) \n",
    "\n",
    "\n",
    "ax_1l.clear()\n",
    "cax_1.cla()\n",
    "z_1l /= (z_1l.sum() * grid.h[0] * grid.h[1])\n",
    "im = ax_1l.pcolormesh(x_, y_, z_1l, cmap='inferno', shading='auto')\n",
    "ax_1l.set_title('Learned solution at time = {:.4f}'.format(t), fontsize=title_size)\n",
    "ax_1l.tick_params(axis='both', which='major', labelsize=tick_size)\n",
    "ax_1l.tick_params(axis='both', which='minor', labelsize=tick_size)\n",
    "cbar = fig_all.colorbar(im, cax=cax_1, ax=ax_1l)\n",
    "cbar.ax.tick_params(labelsize=cbar_tick_size)\n",
    "#cbar.formatter.set_powerlimits((0, 0))\n",
    "ax_1l.set_aspect(\"auto\")\n",
    "plt.savefig('L63-time-one-third.png')\n",
    "\n",
    "# z_2l = fk.make_plot(n_steps, dt, n_repeats, 1, 2, 0)\n",
    "\n",
    "# ax_2l.clear()\n",
    "# cax_2.cla() \n",
    "# z_2l /= (z_2l.sum() *  grid.h[1] * grid.h[2])\n",
    "# im = ax_2l.pcolormesh(y_, z_, z_2l, cmap='inferno')\n",
    "# ax_2l.tick_params(axis='both', which='major', labelsize=tick_size)\n",
    "# ax_2l.tick_params(axis='both', which='minor', labelsize=tick_size)\n",
    "# cbar = fig_all.colorbar(im, cax=cax_2, ax=ax_2l)\n",
    "# cbar.ax.tick_params(labelsize=cbar_tick_size)\n",
    "# #cbar.formatter.set_powerlimits((0, 0))\n",
    "# ax_2l.set_aspect(\"equal\")\n",
    "# plt.savefig('L63-time-two-third.png')\n",
    "\n",
    "# z_3l = fk.make_plot(n_steps, dt, n_repeats, 2, 0, 1)\n",
    "\n",
    "# ax_3l.clear()\n",
    "# cax_3.cla()\n",
    "# z_3l /= (z_3l.sum() *  grid.h[2] * grid.h[0])\n",
    "# im = ax_3l.pcolormesh(z_, x_, z_3l, cmap='inferno')\n",
    "# ax_3l.tick_params(axis='both', which='major', labelsize=tick_size)\n",
    "# ax_3l.tick_params(axis='both', which='minor', labelsize=tick_size)\n",
    "# cbar = fig_all.colorbar(im, cax=cax_3, ax=ax_3l)\n",
    "# cbar.ax.tick_params(labelsize=cbar_tick_size)\n",
    "# #cbar.formatter.set_powerlimits((0, 0))\n",
    "# ax_3l.set_aspect(\"equal\")\n",
    "# fig_all.subplots_adjust(wspace=0.3, hspace=0.2)\n",
    "\n",
    "ax_1l.set_ylabel(r'$p(x, y)$ at time {:.4f}'.format(t), fontsize=title_size)\n",
    "ax_2l.set_ylabel(r'$p(y, z)$ at time {:.4f}'.format(t), fontsize=title_size)\n",
    "ax_3l.set_ylabel(r'$p(z, x)$ at time {:.4f}'.format(t), fontsize=title_size)\n",
    "plt.savefig('L63-time.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111016e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7671b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_m.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_1l.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.h[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "4.8692345 * 0.20537109067143916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-brisbane",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
